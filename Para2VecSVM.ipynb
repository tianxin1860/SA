{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Version=2.0\n",
    "#Using trainData to get doc2vec model\n",
    "#Using doc2vec model to inferrence vector of testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train model Doc2Vec\n",
    "#train vector:1600000\n",
    "#test vector:359\n",
    "#documents = TaggedLineDocument(\"../word2vce/trainAndTest\")\n",
    "#model = gensim.models.Doc2Vec(documents, size=100, window=5, min_count=5, workers=4, dm_mean=1)\n",
    "##Persist a model to disk with:\n",
    "#model.save(\"doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count number of words in vocabulary from word2vec in a sentence\n",
    "#Input: a sentence \n",
    "#Output: number\n",
    "def countWordInVocab(sentence):\n",
    "    num = 0\n",
    "    vocab = word2vec_model.vocab\n",
    "    for word in sentence:\n",
    "        if word in vocab:\n",
    "            num += 1\n",
    "        else:\n",
    "            pass\n",
    "    return num\n",
    "\n",
    "#count number of neg and pos to be deleted\n",
    "#Input: sentences\n",
    "#Output: neg_number, pos_number\n",
    "def cntNumNegPos(sentences):\n",
    "    neg_deleted = 0\n",
    "    pos_deleted = 0\n",
    "    test_deleted = 0\n",
    "    for index, sen in enumerate(sentences):\n",
    "        if countWordInVocab(sen) == 0:\n",
    "            if index < 800000:\n",
    "                neg_deleted += 1\n",
    "            elif index < 1600000:\n",
    "                pos_deleted += 1\n",
    "            else:\n",
    "                test_deleted += 1\n",
    "        else:\n",
    "            pass\n",
    "    return 800000-neg_deleted, 800000-pos_deleted, 359-test_deleted\n",
    "\n",
    "#delete blank sentence\n",
    "#Input:sentences\n",
    "#Output: processed sentences\n",
    "#parameter must be mutable, then can be changed in function\n",
    "def deleteBlankSen(sentences):\n",
    "    return [sen for sen in sentences if countWordInVocab(sen) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "def prepareData():\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    \n",
    "    sentences = gensim.models.word2vec.LineSentence(\"../word2vce/train_text-norm\")\n",
    "    neg_num, pos_num, test_num = cntNumNegPos(sentences)\n",
    "    print(neg_num, pos_num, test_num)\n",
    "    doc2vecCorpus = deleteBlankSen(sentences)\n",
    "    \n",
    "    #把单个句子的每个单词用空格连起来，方便写入文件\n",
    "    finalCorpus = [ \" \".join(sen)  for sen in doc2vecCorpus]\n",
    "    with open(\"doc2vecCorpus.txt\", 'w') as outfile:\n",
    "        outfile.write(\"\\n\".join(finalCorpus))\n",
    "    \n",
    "    documents = TaggedLineDocument(\"doc2vecCorpus.txt\")\n",
    "    doc2vec_model = gensim.models.Doc2Vec(documents, size=300, window=8, min_count=5, \n",
    "                                          workers=4, dm_mean=1, )\n",
    "    ##Persist a model to disk with:\n",
    "    doc2vec_model.save(\"doc2vec.model\")\n",
    "    #model = gensim.models.Doc2Vec.load(\"doc2vec.model\")  # you can continue training with the loaded model!\n",
    "    train_index = [index for index in range(neg_num+pos_num)]\n",
    "    X_train = doc2vec_model.docvecs[train_index]\n",
    "    y_train = [0] * neg_num + [4] * pos_num\n",
    "    #test_index = [ index+neg_num+pos_num for index in range(test_num)]\n",
    "    #X_test = doc2vec_model.docvecs[test_index]\n",
    "\n",
    "    #testData = pd.read_csv(\"../word2vce/testData\", encoding=\"latin-1\", names=[\"label\",\"text\"])\n",
    "    #test_sentences = gensim.models.word2vec.LineSentence(\"../word2vce/test_text-norm\")\n",
    "    #y_test = list(testData['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798531 798396 359\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.models.Word2Vec.load(\"word2vec.model\") \n",
    "prepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec.load(\"doc2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentences = gensim.models.word2vec.LineSentence(\"../word2vce/test_text-norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sen in test_sentences:\n",
    "    X_test.append(model.infer_vector(sen, alpha=0.1, min_alpha=0.0001, steps=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"../word2vce/testData\", encoding=\"latin-1\", names=[\"label\",\"text\"])\n",
    "y_test = list(testData['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# train SVM \n",
    "def train():\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    #clf = svm.SVC(kernel='linear')\n",
    "    clf = svm.LinearSVC(dual=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print(\"number of support vector: %d\\t%d\" %(clf.n_support_[0], clf.n_support_[1]))\n",
    "    return clf\n",
    "    #print SVM information\n",
    "    #clf.n_support_\n",
    "    #clf.dual_coef_\n",
    "    #clf.coef_[0]\n",
    "    \n",
    "def compute_accuracy(y, y_):\n",
    "    result = np.equal(y, y_).astype(int)\n",
    "    return result.mean()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    global y_test\n",
    "    prepareData()\n",
    "    #train the SVM model\n",
    "    clf = train()\n",
    "    #predict\n",
    "    y = clf.predict(X_test)\n",
    "    acc = compute_accuracy(y, y_test)\n",
    "    print(\"accuracy:%f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798531 798396 359\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    word2vec_model = gensim.models.Word2Vec.load(\"word2vec.model\") \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec settings: size=100, window=5, min_count=5, workers=4, alpha=0.025, window=5, min_count=5， sample=0.001, min_alpha=0.0001, sg=0, hs=0, negative=5, cbow_mean=1, \n",
    "iter=5, batch_words=10000\n",
    "| Model                  | Accuracy      | model settings  |\n",
    "| ---------------------- |-------------  | -----|\n",
    "| AvgWord2vecSVM         | 74.0947       | LinearSVC(dual=False)|\n",
    "| AvgWord2vecSVM         | 74.3733       | LinearSVC(dual=False) delete blank 3073 sentence|\n",
    "| ClusterWord2VecSVM     | 66.0167       |   LinearSVC(dual=False)  k=200 |\n",
    "|  NBSVM                 | 77.1588       | liblinear -s 2 n-gram=1|\n",
    "| NBSVM                  | 82.4513       | liblinear -s 2 n-gram=2|\n",
    "| NBSVM                  | 84.1226       | liblinear -s 2 n-gram=3|\n",
    "| NBSVM                  | 83.8440       | liblinear -s 2 n-gram=3|\n",
    "| Para2Vec               | 52.0891       | size=100, window=5, min_count=5, dm_mean=0|\n",
    "| Para2Vec               | 51.2535       | size=100, window=5, min_count=5, dm_mean=1|\n",
    "| Para2Vec               | 50.6964       | size=300, window=5, min_count=5, dm_mean=1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Word2Vec settings: size=1000, window=5, min_count=5, workers=4, alpha=0.025, window=5,\n",
    "    min_count=5， sample=0.00001, min_alpha=0.0001, sg=1, hs=0, negative=5, cbow_mean=1, \n",
    "    iter=5,batch_words=10000\n",
    "\n",
    "\n",
    "| Model                  | Accuracy      | model settings  |\n",
    "| ---------------------- |-------------  | -----|\n",
    "| AvgWord2vecSVM         | 70.4735       | LinearSVC(dual=False) C=0.03 loss='squared_hinge' penalty='L2'|\n",
    "\n",
    "\n",
    "| AvgWord2vecSVM         | 74.0947       | LinearSVC(dual=False) C=0.03 loss='squared_hinge' penalty='L2'|\n",
    "| AvgWord2vecSVM         | 74.3733       | LinearSVC(dual=False) delete blank 3073 sentence|\n",
    "| ClusterWord2VecSVM     | 66.0167       |   LinearSVC(dual=False)  k=200 |\n",
    "|  NBSVM                 | 77.1588       | liblinear -s 2 n-gram=1|\n",
    "| NBSVM                  | 82.4513       | liblinear -s 2 n-gram=2|\n",
    "| NBSVM                  | 84.1226       | liblinear -s 2 n-gram=3|\n",
    "| NBSVM                  | 83.8440       | liblinear -s 2 n-gram=3|\n",
    "| Para2Vec               | 52.0891       | size=100, window=5, min_count=5, dm_mean=0|\n",
    "| Para2Vec               | 51.2535       | size=100, window=5, min_count=5, dm_mean=1|\n",
    "| Para2Vec               | 50.6964       | size=300, window=5, min_count=5, dm_mean=1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597286"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "798531 + 798396 + 359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
